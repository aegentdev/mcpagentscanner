# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. import os
# 3. from dotenv import load_dotenv
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. 
# 3. Security Hardening: Implement input sanitization to prevent prompt injection.
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import os
# 2. import re
# 3. import uuid
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. import logging
# 3. 
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. import streamlit as st
# 3. 
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. from typing import Literal, TypedDict, List
# 3. from langchain_core.messages import BaseMessage
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. 
# 3. Security Recommendation: Sanitize user-provided input to prevent prompt injection.
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. 
# 3. Security Recommendation: Implement input sanitization to prevent prompt injection.
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. from typing import Optional
# 2. from fastapi import FastAPI, HTTPException
# 3. from pydantic import BaseModel
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. 
# 3. Security Mitigation: Sanitize user input to prevent prompt injection.
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import os
# 2. import uuid
# 3. import re
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. Hardened code example demonstrating input sanitization and human-in-the-loop for sensitive tools.
# 2. Import necessary libraries
# 3. from langgraph.graph import StateGraph, END
#
# ğŸ¤– AI Security Analysis Summary
# Generated by AutoHardener with Gemini analysis
#
# Key security improvements:
# 1. import re
# 2. from typing import Literal
# 3. from langgraph.graph import StateGraph
#
import os
from dotenv import load_dotenv
from langchain_core.messages import SystemMessage
from langchain_core.prompts import PromptTemplate

load_dotenv()

sys_msg = SystemMessage(content="""You are a legal support chatbot for SplxAI legal department.
        You are using querying retrieved input documents that describe company's supplier liability contracts, running queries on
        SQL database of employees, jira search and in the end, if the information need is not on JIRA, in employees database or in company's documents, try to use web search for outer
        sources. Howewer, everything regarding company should be found in retrieved supplier liability contracts, employees database or
        in the end, there is already defined JIRA task. If there is no defined JIRA task on this topic, create it.
        You are designed to help SplxAI get information about their legal documents, helping them construct
        new chapters and new legal documents. Also, you should be able to say which employee is already working
        on similar task to help the employee asking the question to respond.
        If you don't know the answear or can't perform an desired action, just respond honestly.
        You should do everything in 5 steps.""")


def make_system_prompt(suffix: str) -> str:
    return (
        "You are a helpful AI assistant, collaborating with other assistants."
        " Use the provided tools to progress towards answering the question."
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        # âš ï¸ Medium risk: open usage detected
        # ğŸ’¡ Sanitize file paths and restrict destinations
        " If you are unable to fully answer, that's OK, another assistant with different tools "
        " will help where you left off. Execute what you can to make progress."
        " If you or any of the other assistants have the final answer or deliverable,"
        " prefix your response with FINAL ANSWER so the team knows to stop."
        f"\n{suffix}"
    )


with open(os.path.join(os.path.dirname(__file__), 'research_prompt.txt'), 'r') as file:
    research_template = file.read()

# research_prompt = PromptTemplate.from_template(research_template)).invoke({"JIRA_project_key": os.getenv('JIRA_project_key')})
    
research_prompt = make_system_prompt(research_template)
